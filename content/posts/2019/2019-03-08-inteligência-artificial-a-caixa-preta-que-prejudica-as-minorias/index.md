---
title: "Inteligência Artificial: a caixa preta que prejudica as minorias"
date: 2019-03-08T23:59:18.254Z
description: Como a inteligência artificial pode prejudicar as minorias e
  ampliar desigualdade de gênero?
language: pt
thumbnail: justice.jpeg
tags:
  - inteligência artificial
  - tecnologia
  - vieses
categories:
  - Inteligência Artificial
draft: false
---
Ao mesmo tempo em que os algoritmos de Inteligência Artificial trazem possibilidades magníficas de otimização do trabalho, personalização da experiência e outras transformações positivas, também trazem riscos e desafios que precisam ser conhecidos e considerados antes de sua adoção.

A possibilidade de criar máquinas inteligentes levanta uma série de questões éticas das quais pouco ouço serem discutidas. É preciso ter claro que esses algoritmos **são programados por pessoas, que injetam nesses códigos visões de mundo e vieses pessoais.** Além disso, esses algoritmos são treinados com um grande volume de dados preexistentes que podem também conter distorções.

Já são muitos os exemplos de algoritmos que reproduzem, por exemplo, discriminação por raça ou gênero. Em um caso emblemático, pesquisadores da **Universidade de Virgínia** demonstraram como algoritmos, treinados com duas grandes bases de dados de fotos comumente utilizadas para este fim, reproduziam preconceitos. Ao analisarem fotos de pessoas nas mais diversas situações, classificaram erroneamente homens como se fossem mulheres quando eles estavam na cozinha.

![Image for post](https://miro.medium.com/max/1274/1*aTMzY5WGw16VBEI9qCXPVQ.png)

Figura do resultado do algoritmo retirado do artigo: <http://vicenteordonez.com/files/bias.pdf>

Outro caso mais recente foi o da **[Amazon](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)** que teve que descontinuar o uso de uma ferramenta de recrutamento que estava penalizando candidatas mulheres. A empresa modificou os programas para torná-los neutros para palavras com gênero. Mas isso não impediu as máquinas de criarem outras maneiras discriminatórias de classificar os candidatos.

Uma das possibilidades levantadas era de que o viés estava presente nos dados utilizados, ou seja, no histórico de decisões de recrutamento da empresa. Afinal, quem eram os entrevistadores por trás das decisões utilizadas no treinamento do algoritmo?

Os cenários descritos anteriormente aconteceram e pessoas já estão sendo prejudicadas e, na maioria dos casos, pertencem as minorias da nossa sociedade.

Se tornará cada vez mais importante desenvolver algoritmos de IA que não sejam apenas poderosos e escaláveis, mas também **transparentes** para inspeção e abertos para a sociedade.

Seria sem dúvida frustrante descobrir que, por exemplo, nenhum banco no mundo deseja aprovar o seu empréstimo sem que ninguém saiba por que, e ninguém possa descobrir.

# Pouca diversidade na área

Um dos primeiros fatos que encontrei foi que, no Brasil, 86% dos profissionais de IA são homens, segundo relatório elaborado pelo **[Fórum Econômico Mundial](https://www.weforum.org/reports/the-global-gender-gap-report-2018).**

![Image for post](https://miro.medium.com/max/1418/1*8A3k_kNUjCMSX_er8vQLcg.png)

Tabela com o a distribuição de profissionais de IA por gênero. Fonte: **[Fórum Econômico Mundial](https://www.weforum.org/reports/the-global-gender-gap-report-2018)**

A pouca quantidade de mulheres é um alerta para problemas já conhecidos sobre a área, como os vieses racistas e sexistas já discutidos.

Se o relatório aponta um aumento da demanda na área de IA, a lacuna de gênero pode causar problemas que não afetam apenas as mulheres. Ainda há poucos profissionais qualificados para a área, e excluir quase metade da população — composta por mulheres — pode prejudicar ainda mais o desenvolvimento do campo.

Sem falar que perdemos um enorme potencial de inovação tecnológica ao termos times nem um pouco diversos atuando na área.

A diversidade das equipes de TI impacta diretamente da IA porque permite a construção de algoritmos com diferentes pontos de vista. *A **diversidade** de conhecimento é o caminho mais assertivo para **inovar** e **remover vieses** culturais.*

> “Quando há diversidade entre os futuros tecnólogos, a prioridade deles é usar a tecnologia para o bem da humanidade.” Fei-Fei Li (Google e Universidade de Stanford)

# Sacrificamos a acurácia por eficiência

Profissionais da área de computação são ensinados a criar códigos e algoritmos eficientes. Durante minha graduação de Sistemas de Informação na USP, tive disciplinas inteiramente dedicadas a análise de algoritmos e otimização de código; mas em uma das únicas matérias que envolviam ética, cultura digital e código aberto, pouco alunos do meu curso frequentavam e alegavam ser uma bobagem termos que discutir “*aquele tipo de assunto”*.

Os casos citados acima, entre inúmeros outros, já deixaram mais do que claro a importância de os profissionais da área estudarem sobre meios eficientes de governança, transparência e controle, inclusive ético, acerca das funções, finalidades e modo de operação de algoritmos de IA.

# Algoritmos automatizam o status quo

Quando pensamos em algoritmos de IA, podemos definir como um conjunto de regras matemáticas que irão automatizar um processo anteriormente realizado por um humano. A tecnologia na verdade não muda a realidade, mas sim potencializa o contexto da realidade que já existe, e automatiza o Status Quo.

![Image for post](https://miro.medium.com/max/1062/0*a5aphHcP9bM-kO7k.jpg)

Resultado do algoritmo **COMPAS** aplicado a 2 pessoas presas por posse de drogas: o homem branco foi classificado como **baixo risco (3)** e a mulher negra como de **alto risco (8)**

O problema é que o *status quo* da nossa sociedade é repleto de preconceitos e julgamentos que podem ter impactos diretos nas oportunidades e nas opções de vida das pessoas, pois deles dependerá o nosso acesso a empregos, crédito, seguro e uma série de outros serviços.

É por esse motivo que Cathy O`Neil, refere-se aos algoritmos como armas matemáticas de destruição, na medida em que, longe de serem neutros e objetivos, embutem em seus códigos uma série de decisões e opiniões que não podem ser contestadas, até porque não são conhecidas.

> Esqueça deles por um minuto, eles podem dizer, e foque em todas as pessoas que conseguem ajuda com os nossos algoritmos de recomendação: que encontram músicas que amam, conseguem o emprego perfeito no Linkedin ou até encontram o amor da vida delas (…) e ignore as imperfeições. **(Cathy O’Neil — Weapons of Math Destruction)**

- - -

# Caminhos e conclusões

Como vimos, a inteligência artificial tende a ocupar um papel cada vez mais crucial em nosso cotidiano. Algoritmos poderão decidir quem tem acesso a um empréstimo ou não, quem deve ir para cadeia ou não e quais pessoas devem ter acesso a determinadas informações. A IA não é só mais uma tendência, e sim um mecanismo poderoso de mudança social.

## Diversidade, inclusão e democratização de conhecimento

Apesar de a IA está cada vez mais útil e fácil de usar, falta deixá-la ao alcance de todos. A inclusão na IA significa fazer com que as ferramentas sejam acessíveis para todos, não só para os *nerds* da matemática.

A democratização do aprendizado de máquina é o assunto do momento, mas eu realmente acredito nisso. Tenho como missão pessoal democratizar esse conhecimento na tentativa de trazer diversidade para essa área. Temos que mostrar para todas as mulheres e outras minorias dentro de TI que a IA não é mágica. É matemática.

A IA precisa aprender com o ser humano e, por isso, é importante que esse conhecimento não seja realizado apenas a partir de um ponto de vista. Precisamos investir na diversidade das equipes de programação que trabalham com inteligência artificial.

Seja a sua diversidade de gênero, regional, de estudo, classe social, cor da pele, ou qualquer outra você certamente passou por situações desconfortáveis que exigem muito mais força de vontade para seguir carreira dentro de uma área tão pouco acolhedora. Mas não desista por isso, precisamos de pessoas como você reprogramando o futuro.

## Dados abertos

Iniciativas como a [Diversity.ai](http://DIVErsity.ai) e [OpenAI](https://openai.com/) defendem que os algoritmos de IA devem ser auditáveis. É preciso conhecer quais bases de dados foram utilizadas para seu treinamento e quais são os critérios utilizados para processá-las, pois só assim a sociedade estará segura para poder ter controle sobre as decisões que afetam suas vidas.

No Brasil, já existem iniciativas para a construção de grandes **bases de dados compartilhadas e abertas** ([Serenata.ai](https://serenata.ai/) e [Colaboradados](https://colaboradados.github.io/)) para que diferentes algoritmos possam utilizá-las em seu treinamento e para que eventuais vieses sejam passíveis de identificação e correção por todos.

Com as máquinas, esperamos eliminar muitos dos preconceitos ou processos subconscientes que afetam o pensamento humano ou, pelo menos, reconhecê-los com mais facilidade quando eles aparecerem. Precisamos ampliar o nosso conhecimento e interesse sobre o funcionamento dessas novas tecnologias, assim como criarmos mecanismos e regras para seu uso, de modo a ter controle sobre o aumento de seu poder de influência sobre os usuários e não dependermos de caixas pretas sobre as quais não temos nenhum controle.

#### Dicas de conteúdo para assistir, ouvir e ler

#### **[Bias em Ciência de Dado](http://lgmoneda.github.io/2019/01/14/bias-data-science.html "http\://lgmoneda.github.io/2019/01/14/bias-data-science.html")**

**[The Global Gender Gap Report 201](https://www.weforum.org/reports/the-global-gender-gap-report-2018 "https\://www.weforum.org/reports/the-global-gender-gap-report-2018")**

**[Desafios em Machine Learning — Hipsters #137 — Hipsters Ponto Tec](https://hipsters.tech/desafios-em-machine-learning-hipsters-137/ "https\://hipsters.tech/desafios-em-machine-learning-hipsters-137/")**

[**A inteligência artificial precisa aprender com o mundo real | Google**](https://about.google/stories/gender-balance-diversity-important-to-machine-learning/?hl=pt-BR "https\://about.google/stories/gender-balance-diversity-important-to-machine-learning/?hl=pt-BR")